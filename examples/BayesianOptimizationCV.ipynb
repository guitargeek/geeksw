{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayesianOptimizationCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from geeksw.geeklearn.model_selection import BayesianOptimizationCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=10000, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params = dict(early_stopping_rounds=10, eval_metric=\"auc\", seed=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(**base_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_bounds = {'learning_rate': (0, 1), \"gamma\": (0, 1), \"reg_lambda\": (0,1), \"max_depth\": (2,9)}\n",
    "int_params= [\"max_depth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = BayesianOptimizationCV(model, param_bounds, int_params=int_params,\n",
    "                            n_iter=10, cv=3, return_train_score=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   gamma   | learni... | max_depth | reg_la... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9442  \u001b[0m | \u001b[0m 0.999   \u001b[0m | \u001b[0m 0.5526  \u001b[0m | \u001b[0m 6.557   \u001b[0m | \u001b[0m 0.03333 \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.9434  \u001b[0m | \u001b[0m 0.8522  \u001b[0m | \u001b[0m 0.6692  \u001b[0m | \u001b[0m 6.718   \u001b[0m | \u001b[0m 0.02793 \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8979  \u001b[0m | \u001b[0m 0.04333 \u001b[0m | \u001b[0m 0.005373\u001b[0m | \u001b[0m 2.03    \u001b[0m | \u001b[0m 0.9233  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.9452  \u001b[0m | \u001b[95m 0.9508  \u001b[0m | \u001b[95m 0.005093\u001b[0m | \u001b[95m 8.947   \u001b[0m | \u001b[95m 0.9761  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.9469  \u001b[0m | \u001b[95m 0.1211  \u001b[0m | \u001b[95m 0.006471\u001b[0m | \u001b[95m 8.985   \u001b[0m | \u001b[95m 0.0018  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.9445  \u001b[0m | \u001b[0m 0.9899  \u001b[0m | \u001b[0m 0.9794  \u001b[0m | \u001b[0m 8.964   \u001b[0m | \u001b[0m 0.1168  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.9524  \u001b[0m | \u001b[95m 0.9949  \u001b[0m | \u001b[95m 0.03785 \u001b[0m | \u001b[95m 8.807   \u001b[0m | \u001b[95m 0.008313\u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.4999  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 1.758e-0\u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.4999  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 7.662   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9329  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.934   \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.325962</td>\n",
       "      <td>0.095801</td>\n",
       "      <td>0.007097</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.999014</td>\n",
       "      <td>0.552635</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.033327</td>\n",
       "      <td>{'gamma': 0.9990137177335074, 'learning_rate':...</td>\n",
       "      <td>0.943911</td>\n",
       "      <td>0.942694</td>\n",
       "      <td>0.945995</td>\n",
       "      <td>0.944200</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>0.999400</td>\n",
       "      <td>0.99970</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.323778</td>\n",
       "      <td>0.047338</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.852222</td>\n",
       "      <td>0.669214</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.027928</td>\n",
       "      <td>{'gamma': 0.8522220884120268, 'learning_rate':...</td>\n",
       "      <td>0.946611</td>\n",
       "      <td>0.939994</td>\n",
       "      <td>0.943594</td>\n",
       "      <td>0.943400</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.490008</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.043329</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.923256</td>\n",
       "      <td>{'gamma': 0.04332920220854686, 'learning_rate'...</td>\n",
       "      <td>0.907618</td>\n",
       "      <td>0.893189</td>\n",
       "      <td>0.892889</td>\n",
       "      <td>0.897899</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>8</td>\n",
       "      <td>0.895290</td>\n",
       "      <td>0.901455</td>\n",
       "      <td>0.902655</td>\n",
       "      <td>0.89980</td>\n",
       "      <td>0.003227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.209649</td>\n",
       "      <td>0.168376</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.950757</td>\n",
       "      <td>0.005093</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.976052</td>\n",
       "      <td>{'gamma': 0.9507571496730528, 'learning_rate':...</td>\n",
       "      <td>0.947211</td>\n",
       "      <td>0.941494</td>\n",
       "      <td>0.946895</td>\n",
       "      <td>0.945200</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>3</td>\n",
       "      <td>0.962196</td>\n",
       "      <td>0.964302</td>\n",
       "      <td>0.961902</td>\n",
       "      <td>0.96280</td>\n",
       "      <td>0.001069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.121219</td>\n",
       "      <td>0.038874</td>\n",
       "      <td>0.016388</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.121148</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>{'gamma': 0.12114849835832986, 'learning_rate'...</td>\n",
       "      <td>0.948410</td>\n",
       "      <td>0.944194</td>\n",
       "      <td>0.948095</td>\n",
       "      <td>0.946900</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>2</td>\n",
       "      <td>0.965647</td>\n",
       "      <td>0.969252</td>\n",
       "      <td>0.964002</td>\n",
       "      <td>0.96630</td>\n",
       "      <td>0.002192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.672523</td>\n",
       "      <td>0.055908</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.989932</td>\n",
       "      <td>0.979412</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.116785</td>\n",
       "      <td>{'gamma': 0.9899315536352928, 'learning_rate':...</td>\n",
       "      <td>0.947211</td>\n",
       "      <td>0.944194</td>\n",
       "      <td>0.942094</td>\n",
       "      <td>0.944500</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.99995</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.091377</td>\n",
       "      <td>0.022283</td>\n",
       "      <td>0.016471</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.994882</td>\n",
       "      <td>0.037849</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>{'gamma': 0.9948820633483003, 'learning_rate':...</td>\n",
       "      <td>0.956209</td>\n",
       "      <td>0.949295</td>\n",
       "      <td>0.951695</td>\n",
       "      <td>0.952400</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982598</td>\n",
       "      <td>0.982901</td>\n",
       "      <td>0.982151</td>\n",
       "      <td>0.98255</td>\n",
       "      <td>0.000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.083443</td>\n",
       "      <td>0.016410</td>\n",
       "      <td>0.011314</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>{'gamma': 0.9999982418052585, 'learning_rate':...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499850</td>\n",
       "      <td>0.499850</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>9</td>\n",
       "      <td>0.499850</td>\n",
       "      <td>0.499925</td>\n",
       "      <td>0.499925</td>\n",
       "      <td>0.49990</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.759339</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>0.010473</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'gamma': 0.0, 'learning_rate': 0.0, 'max_dept...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499850</td>\n",
       "      <td>0.499850</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>10</td>\n",
       "      <td>0.499850</td>\n",
       "      <td>0.499925</td>\n",
       "      <td>0.499925</td>\n",
       "      <td>0.49990</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.649842</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.007134</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'gamma': 1.0, 'learning_rate': 1.0, 'max_dept...</td>\n",
       "      <td>0.937612</td>\n",
       "      <td>0.925593</td>\n",
       "      <td>0.935494</td>\n",
       "      <td>0.932900</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>7</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>0.997000</td>\n",
       "      <td>0.998350</td>\n",
       "      <td>0.99705</td>\n",
       "      <td>0.001042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_gamma  \\\n",
       "0       1.325962      0.095801         0.007097        0.000574     0.999014   \n",
       "1       1.323778      0.047338         0.007274        0.000795     0.852222   \n",
       "2       0.490008      0.014006         0.004698        0.000331     0.043329   \n",
       "3       2.209649      0.168376         0.012139        0.000703     0.950757   \n",
       "4       2.121219      0.038874         0.016388        0.000100     0.121148   \n",
       "5       1.672523      0.055908         0.004375        0.000154     0.989932   \n",
       "6       2.091377      0.022283         0.016471        0.000571     0.994882   \n",
       "7       2.083443      0.016410         0.011314        0.000466     0.999998   \n",
       "8       1.759339      0.033230         0.010473        0.000443     0.000000   \n",
       "9       0.649842      0.006812         0.007134        0.000302     1.000000   \n",
       "\n",
       "   param_learning_rate  param_max_depth  param_reg_lambda  \\\n",
       "0             0.552635              6.0          0.033327   \n",
       "1             0.669214              6.0          0.027928   \n",
       "2             0.005373              2.0          0.923256   \n",
       "3             0.005093              8.0          0.976052   \n",
       "4             0.006471              8.0          0.001800   \n",
       "5             0.979412              8.0          0.116785   \n",
       "6             0.037849              8.0          0.008313   \n",
       "7             0.000000              8.0          0.000002   \n",
       "8             0.000000              7.0          1.000000   \n",
       "9             1.000000              3.0          0.000000   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'gamma': 0.9990137177335074, 'learning_rate':...           0.943911   \n",
       "1  {'gamma': 0.8522220884120268, 'learning_rate':...           0.946611   \n",
       "2  {'gamma': 0.04332920220854686, 'learning_rate'...           0.907618   \n",
       "3  {'gamma': 0.9507571496730528, 'learning_rate':...           0.947211   \n",
       "4  {'gamma': 0.12114849835832986, 'learning_rate'...           0.948410   \n",
       "5  {'gamma': 0.9899315536352928, 'learning_rate':...           0.947211   \n",
       "6  {'gamma': 0.9948820633483003, 'learning_rate':...           0.956209   \n",
       "7  {'gamma': 0.9999982418052585, 'learning_rate':...           0.500000   \n",
       "8  {'gamma': 0.0, 'learning_rate': 0.0, 'max_dept...           0.500000   \n",
       "9  {'gamma': 1.0, 'learning_rate': 1.0, 'max_dept...           0.937612   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.942694           0.945995         0.944200        0.001363   \n",
       "1           0.939994           0.943594         0.943400        0.002705   \n",
       "2           0.893189           0.892889         0.897899        0.006874   \n",
       "3           0.941494           0.946895         0.945200        0.002623   \n",
       "4           0.944194           0.948095         0.946900        0.001917   \n",
       "5           0.944194           0.942094         0.944500        0.002100   \n",
       "6           0.949295           0.951695         0.952400        0.002866   \n",
       "7           0.499850           0.499850         0.499900        0.000071   \n",
       "8           0.499850           0.499850         0.499900        0.000071   \n",
       "9           0.925593           0.935494         0.932900        0.005239   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                5            1.000000            0.999700   \n",
       "1                6            1.000000            1.000000   \n",
       "2                8            0.895290            0.901455   \n",
       "3                3            0.962196            0.964302   \n",
       "4                2            0.965647            0.969252   \n",
       "5                4            1.000000            0.999850   \n",
       "6                1            0.982598            0.982901   \n",
       "7                9            0.499850            0.499925   \n",
       "8               10            0.499850            0.499925   \n",
       "9                7            0.995800            0.997000   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.999400           0.99970         0.000245  \n",
       "1            1.000000           1.00000         0.000000  \n",
       "2            0.902655           0.89980         0.003227  \n",
       "3            0.961902           0.96280         0.001069  \n",
       "4            0.964002           0.96630         0.002192  \n",
       "5            1.000000           0.99995         0.000071  \n",
       "6            0.982151           0.98255         0.000308  \n",
       "7            0.499925           0.49990         0.000035  \n",
       "8            0.499925           0.49990         0.000035  \n",
       "9            0.998350           0.99705         0.001042  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
